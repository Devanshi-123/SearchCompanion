{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/TsqymUSIAUwIXrdWvaBp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Devanshi-123/SearchCompanion/blob/gh-pages/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ1NMloqulsg",
        "colab_type": "text"
      },
      "source": [
        "Cats And Dogs Classification -Deep Learning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "am3OSzCBjANy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "d70683b0-06d3-411d-ffdd-84a85f51ae41"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVVanv59kFke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q keras"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRme3iggkWwx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a64e7cd8-2aba-45eb-d263-df2a8b53ac21"
      },
      "source": [
        "import keras"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DvNDnvukkaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing all te req lib\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing import image\n",
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7GgRK-Cn_29",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4a48287-04f5-497e-f917-d247a2532ce4"
      },
      "source": [
        "! ls /content/drive/My\\ Drive/dataset"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_set  training_set\tvalidation_set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daXiQL50oOmi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09fe52b9-2b97-4bea-e235-e2c8fa2092a2"
      },
      "source": [
        "! ls /content/drive/My\\ Drive/dataset/training_set\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cats  dogs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7_h6IHalS5R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dimensions of our images.\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "#defining the data directories\n",
        "train_data_dir= '/content/drive/My Drive/dataset/training_set'\n",
        "validation_data_dir= '/content/drive/My Drive/dataset/validation_set'\n",
        "n_training_sample= 4000\n",
        "n_validation_sample= 1000\n",
        "epochs=40\n",
        "batch_size=10"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts_GadbFldbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "    input_shape = (3, img_width, img_height)\n",
        "else:\n",
        "    input_shape = (img_width, img_height,3)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUZtXeZBlqzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining the model\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(2, activation=tf.nn.sigmoid)])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Bpo_VHlvyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining the optimizer and metrics\n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdnm-1wXl0w5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c128b805-7d1d-4013-d899-f00756836701"
      },
      "source": [
        "\n",
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=n_training_sample // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=n_validation_sample // batch_size)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8006 images belonging to 2 classes.\n",
            "Found 1002 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From <ipython-input-31-a5735ad70afb>:30: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/40\n",
            "400/400 [==============================] - 932s 2s/step - loss: 0.7088 - accuracy: 0.5010 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 2/40\n",
            "400/400 [==============================] - 396s 991ms/step - loss: 0.6931 - accuracy: 0.4985 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/40\n",
            "400/400 [==============================] - 236s 590ms/step - loss: 0.6931 - accuracy: 0.5025 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 4/40\n",
            "400/400 [==============================] - 152s 380ms/step - loss: 0.6931 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 5/40\n",
            "400/400 [==============================] - 100s 249ms/step - loss: 0.6931 - accuracy: 0.5107 - val_loss: 0.6931 - val_accuracy: 0.5010\n",
            "Epoch 6/40\n",
            "400/400 [==============================] - 78s 194ms/step - loss: 0.6931 - accuracy: 0.5005 - val_loss: 0.6931 - val_accuracy: 0.5010\n",
            "Epoch 7/40\n",
            "400/400 [==============================] - 65s 163ms/step - loss: 0.6931 - accuracy: 0.5075 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 8/40\n",
            "400/400 [==============================] - 60s 149ms/step - loss: 0.6931 - accuracy: 0.5063 - val_loss: 0.6931 - val_accuracy: 0.5010\n",
            "Epoch 9/40\n",
            "400/400 [==============================] - 56s 140ms/step - loss: 0.6931 - accuracy: 0.5038 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 10/40\n",
            "400/400 [==============================] - 56s 140ms/step - loss: 0.6931 - accuracy: 0.4960 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 11/40\n",
            "400/400 [==============================] - 55s 137ms/step - loss: 0.6931 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
            "Epoch 12/40\n",
            "400/400 [==============================] - 55s 137ms/step - loss: 0.6931 - accuracy: 0.5033 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
            "Epoch 13/40\n",
            "400/400 [==============================] - 54s 135ms/step - loss: 0.6931 - accuracy: 0.4877 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
            "Epoch 14/40\n",
            "400/400 [==============================] - 54s 135ms/step - loss: 0.6931 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 15/40\n",
            "400/400 [==============================] - 54s 135ms/step - loss: 0.6931 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5010\n",
            "Epoch 16/40\n",
            "400/400 [==============================] - 54s 134ms/step - loss: 0.6931 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 17/40\n",
            "400/400 [==============================] - 55s 138ms/step - loss: 0.6931 - accuracy: 0.4983 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 18/40\n",
            "400/400 [==============================] - 55s 137ms/step - loss: 0.6931 - accuracy: 0.4985 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 19/40\n",
            "400/400 [==============================] - 54s 136ms/step - loss: 0.6931 - accuracy: 0.4920 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 20/40\n",
            "400/400 [==============================] - 54s 136ms/step - loss: 0.6931 - accuracy: 0.4907 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 21/40\n",
            "400/400 [==============================] - 54s 136ms/step - loss: 0.6931 - accuracy: 0.4940 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 22/40\n",
            "400/400 [==============================] - 54s 135ms/step - loss: 0.6931 - accuracy: 0.5045 - val_loss: 0.6931 - val_accuracy: 0.5010\n",
            "Epoch 23/40\n",
            "400/400 [==============================] - 56s 139ms/step - loss: 0.6931 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 24/40\n",
            "400/400 [==============================] - 54s 135ms/step - loss: 0.6931 - accuracy: 0.4947 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 25/40\n",
            "400/400 [==============================] - 54s 134ms/step - loss: 0.6931 - accuracy: 0.4955 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 26/40\n",
            "400/400 [==============================] - 54s 135ms/step - loss: 0.6931 - accuracy: 0.5050 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 27/40\n",
            "400/400 [==============================] - 54s 135ms/step - loss: 0.6931 - accuracy: 0.4975 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
            "Epoch 28/40\n",
            "400/400 [==============================] - 54s 134ms/step - loss: 0.6931 - accuracy: 0.4935 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
            "Epoch 29/40\n",
            "400/400 [==============================] - 55s 137ms/step - loss: 0.6931 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
            "Epoch 30/40\n",
            "400/400 [==============================] - 54s 135ms/step - loss: 0.6931 - accuracy: 0.4980 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
            "Epoch 31/40\n",
            "400/400 [==============================] - 54s 135ms/step - loss: 0.6931 - accuracy: 0.4965 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 32/40\n",
            "400/400 [==============================] - 54s 136ms/step - loss: 0.6931 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 33/40\n",
            "400/400 [==============================] - 54s 134ms/step - loss: 0.6931 - accuracy: 0.4982 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
            "Epoch 34/40\n",
            "400/400 [==============================] - 55s 137ms/step - loss: 0.6931 - accuracy: 0.4945 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 35/40\n",
            "400/400 [==============================] - 55s 139ms/step - loss: 0.6931 - accuracy: 0.4908 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
            "Epoch 36/40\n",
            "400/400 [==============================] - 55s 137ms/step - loss: 0.6931 - accuracy: 0.5010 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
            "Epoch 37/40\n",
            "400/400 [==============================] - 55s 137ms/step - loss: 0.6931 - accuracy: 0.5052 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 38/40\n",
            "400/400 [==============================] - 55s 138ms/step - loss: 0.6931 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 39/40\n",
            "400/400 [==============================] - 55s 137ms/step - loss: 0.6931 - accuracy: 0.4967 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
            "Epoch 40/40\n",
            "400/400 [==============================] - 55s 138ms/step - loss: 0.6931 - accuracy: 0.4952 - val_loss: 0.6931 - val_accuracy: 0.4990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7ce0c43f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCpXHavfrEAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "800e1270-52e9-472e-b36c-7b2dfa901684"
      },
      "source": [
        "\n",
        "#testing the model\n",
        "pred= image.load_img('/content/drive/My Drive/dataset/test_set/cats/cat.4502.jpg', target_size=(150,150))\n",
        "pred=image.img_to_array(pred)\n",
        "pred= np.expand_dims(pred, axis=0)\n",
        "result= model.predict(pred)\n",
        "print(result)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}